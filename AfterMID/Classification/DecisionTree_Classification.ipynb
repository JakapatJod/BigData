{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPh/J8q1PpjWIiL42uFMSzS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gyrTruQ69TaY","executionInfo":{"status":"ok","timestamp":1727095978519,"user_tz":-420,"elapsed":58717,"user":{"displayName":"JAKAPAT JODDUANGCHAN","userId":"12689596023016194899"}},"outputId":"de83a00c-c313-41d8-a427-f69a182847a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyspark\n","  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=9bbba622151a6cc833f57416cc46a302accb280bb1fad8cf7663c04d6e5d20f1\n","  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","Successfully installed pyspark-3.5.2\n"]}],"source":["!pip install pyspark"]},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder\n","from pyspark.ml.classification import DecisionTreeClassifier\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","from pyspark.ml import Pipeline\n","\n","spark = SparkSession.builder.appName(\"DecisionTree_Classification\").getOrCreate()\n","# สร้าง SparkSession และตั้งชื่อแอปพลิเคชันว่า \"DecisionTree_Classification\"\n","\n","data = spark.read.csv(\"fb_live_thailand.csv\", header=True, inferSchema=True)\n","# โหลดข้อมูลจากไฟล์ CSV เข้าสู่ DataFrame โดยมีแถวแรกเป็นชื่อคอลัมน์ และให้ Spark ตรวจจับประเภทข้อมูลอัตโนมัติ\n","\n","status_type_indexer = StringIndexer(inputCol=\"status_type\", outputCol=\"status_type_ind\")\n","# สร้าง StringIndexer เพื่อแปลงคอลัมน์ 'status_type' เป็นดัชนีใหม่ 'status_type_ind'\n","\n","status_published_indexer = StringIndexer(inputCol=\"status_published\", outputCol=\"status_published_ind\")\n","# สร้าง StringIndexer เพื่อแปลงคอลัมน์ 'status_published' เป็นดัชนีใหม่ 'status_published_ind'\n","\n","status_type_encoder = OneHotEncoder(inputCol=\"status_type_ind\", outputCol=\"status_type_encoded\")\n","# สร้าง OneHotEncoder เพื่อแปลงดัชนี 'status_type_ind' เป็นข้อมูล Boolean ในคอลัมน์ 'status_type_encoded'\n","\n","status_published_encoder = OneHotEncoder(inputCol=\"status_published_ind\", outputCol=\"status_published_encoded\")\n","# สร้าง OneHotEncoder เพื่อแปลงดัชนี 'status_published_ind' เป็นข้อมูล Boolean ในคอลัมน์ 'status_published_encoded'\n","\n","assembler = VectorAssembler(inputCols=[\"status_type_encoded\", \"status_published_encoded\"], outputCol=\"features\")\n","# รวมฟีเจอร์ที่เข้ารหัสไว้ในเวกเตอร์ในคอลัมน์ 'features'\n","\n","pipeline = Pipeline(stages=[status_type_indexer, status_published_indexer, status_type_encoder, status_published_encoder, assembler])\n","# สร้าง pipeline ที่รวมทุกขั้นตอนที่ได้ทำไว้ในรูปแบบลำดับขั้นตอน\n","\n","pipeline_model = pipeline.fit(data)\n","# ฟิตข้อมูลเข้าสู่ pipeline เพื่อสร้างโมเดล pipeline\n","\n","transformed_data = pipeline_model.transform(data)\n","# ใช้ pipeline model เพื่อแปลงข้อมูลและสร้าง DataFrame ใหม่ที่มีฟีเจอร์ใหม่\n","\n","train_data, test_data = transformed_data.randomSplit([0.8, 0.2])\n","# แบ่งข้อมูลที่แปลงแล้วออกเป็นชุดการฝึก (80%) และชุดทดสอบ (20%)\n","\n","decision_tree = DecisionTreeClassifier(labelCol=\"status_type_ind\", featuresCol=\"features\")\n","# สร้างโมเดล Decision Tree โดยใช้ 'status_type_ind' เป็นคอลัมน์เป้าหมายและ 'features' เป็นฟีเจอร์\n","\n","decision_tree_model = decision_tree.fit(train_data)\n","# ฟิตโมเดลด้วยชุดข้อมูลการฝึก\n","\n","predictions = decision_tree_model.transform(test_data)\n","# ใช้โมเดลที่ฟิตแล้วเพื่อทำการทำนายชุดข้อมูลทดสอบ\n","\n","evaluator = MulticlassClassificationEvaluator(labelCol=\"status_type_ind\", predictionCol=\"prediction\")\n","# สร้าง evaluator สำหรับประเมินผลลัพธ์การทำนายโดยใช้คอลัมน์เป้าหมายและคอลัมน์การทำนาย\n","\n","accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n","# ประเมินความแม่นยำของโมเดล\n","\n","precision = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})\n","# ประเมินความแม่นยำเชิงสัมพันธ์ของโมเดล\n","\n","recall = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"})\n","# ประเมินการเรียกคืนของโมเดล\n","\n","f1 = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})\n","# ประเมินค่า F1 ของโมเดล\n","\n","test_error = 1.0 - accuracy\n","# คำนวณค่า Test Error โดยการลบความแม่นยำจาก 1\n","\n","print(f\"Accuracy: {accuracy}\")\n","# แสดงผลความแม่นยำ\n","\n","print(f\"Precision: {precision}\")\n","# แสดงผลความแม่นยำเชิงสัมพันธ์\n","\n","print(f\"Recall: {recall}\")\n","# แสดงผลการเรียกคืน\n","\n","print(f\"F1 Measure: {f1}\")\n","# แสดงผลค่า F1\n","\n","print(f\"Test Error: {test_error}\")\n","# แสดงผลค่า Test Error\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VmyKkPei-A6-","executionInfo":{"status":"ok","timestamp":1727096237758,"user_tz":-420,"elapsed":20882,"user":{"displayName":"JAKAPAT JODDUANGCHAN","userId":"12689596023016194899"}},"outputId":"bed3742b-ad65-43ff-a2d3-fed0303f2ba3"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 1.0\n","Precision: 1.0\n","Recall: 1.0\n","F1 Measure: 1.0\n","Test Error: 0.0\n"]}]}]}